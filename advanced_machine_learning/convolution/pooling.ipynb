{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When padding is a list, it must be of size 4. Received: padding=[[0, 0], [0, 0]] of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAfter Dilation (padding size 2x2, stride 1x1):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.numpy())\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mdilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mdilation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdilation\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     dilation_model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mX_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# model_reshape = dilation_model(X_reshaped)\u001b[39;00m\n\u001b[32m     44\u001b[39m \n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# Reshape back to 2D\u001b[39;00m\n\u001b[32m     46\u001b[39m     result = tf.reshape(dilation_model, [-\u001b[32m1\u001b[39m, dilation_model.shape[\u001b[32m2\u001b[39m]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py312/lib/python3.12/site-packages/tensorflow/python/ops/nn_ops.py:1975\u001b[39m, in \u001b[36mconvert_padding\u001b[39m\u001b[34m(padding, expected_length)\u001b[39m\n\u001b[32m   1973\u001b[39m     explicit_paddings.extend(dim_paddings)\n\u001b[32m   1974\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(padding) != expected_length:\n\u001b[32m-> \u001b[39m\u001b[32m1975\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1976\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhen padding is a list, it must be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1977\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: padding=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadding\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(padding)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1978\u001b[39m   padding = \u001b[33m\"\u001b[39m\u001b[33mEXPLICIT\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1979\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m padding, explicit_paddings\n",
      "\u001b[31mValueError\u001b[39m: When padding is a list, it must be of size 4. Received: padding=[[0, 0], [0, 0]] of size 2"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import MaxPooling2D\n",
    "# from tensorflow.keras\n",
    " \n",
    "# Define the input tensor\n",
    "X = tf.constant([\n",
    "    [3, 0, 1, 2, 7, 4],\n",
    "    [1, 5, 8, 9, 3, 1],\n",
    "    [2, 7, 2, 5, 1, 3],\n",
    "    [0, 1, 3, 1, 7, 8],\n",
    "    [4, 2, 1, 6, 2, 8],\n",
    "    [2, 4, 5, 2, 3, 9]\n",
    "])\n",
    "\n",
    "filter = tf.constant([[[[1]], [[0]], [[-1]]],\n",
    "                      [[[1]], [[0]], [[-1]]],\n",
    "                      [[[1]], [[0]], [[-1]]]], dtype=tf.float32)\n",
    " \n",
    "# Reshape the tensor to have batch and channel dimensions\n",
    "X_reshaped = tf.reshape(X, [1, 6, 6, 1])\n",
    " \n",
    "def maxPooling():\n",
    "    # Create the max pooling layer\n",
    "    max_pool_layer = MaxPooling2D(\n",
    "        pool_size=2,    # Pool size: 2x2\n",
    "        strides=1,      # Stride: 1x1\n",
    "        padding='valid'      # No padding\n",
    "    )\n",
    "    \n",
    "    # Apply pooling\n",
    "    max_pooled = max_pool_layer(X_reshaped)\n",
    "    \n",
    "    # Reshape back to 2D\n",
    "    result = tf.reshape(max_pooled, [-1, max_pooled.shape[2]])\n",
    "    \n",
    "    print(\"Original array:\")\n",
    "    print(X.numpy())\n",
    "    print(\"\\nAfter max pooling (pool size 2x2, stride 1x1):\")\n",
    "    print(result.numpy())\n",
    " \n",
    "def dilation():\n",
    "    dilation_model = tf.nn.conv2d(input=X_reshaped,padding=[[0,0],[0,0]],filters=filter, strides=1, dilations=2)\n",
    "    # model_reshape = dilation_model(X_reshaped)\n",
    "    \n",
    "    # Reshape back to 2D\n",
    "    result = tf.reshape(dilation_model, [-1, dilation_model.shape[2]])\n",
    "    \n",
    "    print(\"Original array:\")\n",
    "    print(X.numpy())\n",
    "    print(\"\\nAfter Dilation (padding size 2x2, stride 1x1):\")\n",
    "    print(result.numpy())\n",
    "\n",
    "dilation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding=VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[[3 0 1 2 7 4]\n",
      " [1 5 8 9 3 1]\n",
      " [2 7 2 5 1 3]\n",
      " [0 1 3 1 7 8]\n",
      " [4 2 1 6 2 8]\n",
      " [2 4 5 2 3 9]]\n",
      "\n",
      "Convolution kernel:\n",
      "[[[-1.]\n",
      "  [-1.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[-1.]\n",
      "  [-1.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[-1.]\n",
      "  [-1.]\n",
      "  [ 1.]]]\n",
      "\n",
      "After convolution (kernel size 3x3, stride 1x1, padding=SAME):\n",
      "[[  0.   4.   0.  -8.]\n",
      " [  0.   6.   0. -12.]\n",
      " [  0.   6.   0. -12.]\n",
      " [  0.   4.   0.  -8.]]\n"
     ]
    }
   ],
   "source": [
    "data1 = tf.constant([\n",
    "    [0,0,2,2],\n",
    "    [0,0,2,2],\n",
    "    [0,0,2,2],\n",
    "    [0,0,2,2]\n",
    "], dtype=tf.float32)\n",
    "X_reshaped = tf.reshape(data1, [1,4,4,1])\n",
    "# print(data1_reshape)\n",
    "\n",
    "# Define the custom kernel\n",
    "kernel = tf.constant([\n",
    "    [-1, -1, 1],  \n",
    "    [-1, -1, 1],  \n",
    "    [-1, -1, 1],  \n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Reshape the kernel to the format expected by tf.nn.conv2d [filter_height, filter_width, in_channels, out_channels]\n",
    "kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "# Reshape the kernel to the format expected by tf.nn.conv2d [filter_height, filter_width, in_channels, out_channels]\n",
    "# kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "# Apply convolution with padding='SAME' (which adds padding of 1) and stride of 2\n",
    "conv_result = tf.nn.conv2d(\n",
    "    input=X_reshaped,\n",
    "    filters=kernel,\n",
    "    strides=[1, 1, 1, 1],  # Stride of 2 in both height and width dimensions\n",
    "    padding='SAME'         # Adds padding as needed (effectively padding of 1)\n",
    ")\n",
    "\n",
    "# Reshape back to 2D\n",
    "result = tf.reshape(conv_result, [-1, conv_result.shape[2]])\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(X.numpy())\n",
    "print(\"\\nConvolution kernel:\")\n",
    "print(tf.reshape(kernel, [3, 3, 1]).numpy())\n",
    "print(\"\\nAfter convolution (kernel size 3x3, stride 1x1, padding=SAME):\")\n",
    "print(result.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
